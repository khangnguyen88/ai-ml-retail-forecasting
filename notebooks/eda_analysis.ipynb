{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Retail Demand Forecasting\n",
    "\n",
    "This notebook performs comprehensive EDA on the retail pricing and demand dataset to identify:\n",
    "1. Main demand drivers (price, promo, holiday, weather, patterns)\n",
    "2. Price elasticity by SKU and promo effect sizes\n",
    "3. Stockout detection and impact on demand estimation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "try:\n",
    "    df = pd.read_csv('../retail_pricing_demand_2024.csv')\n",
    "    print(f\"âœ“ Full dataset loaded: {len(df):,} rows\")\n",
    "except:\n",
    "    try:\n",
    "        df = pd.read_csv('../retail_pricing_demand_2024_sample.csv')\n",
    "        print(f\"âœ“ Sample dataset loaded: {len(df):,} rows\")\n",
    "    except:\n",
    "        # Try without going up a directory\n",
    "        df = pd.read_csv('retail_pricing_demand_2024_sample.csv')\n",
    "        print(f\"âœ“ Sample dataset loaded: {len(df):,} rows\")\n",
    "\n",
    "# Convert date column\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\nDate range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"Stores: {df['store_id'].nunique()} unique\")\n",
    "print(f\"SKUs: {df['sku_id'].nunique()} unique\")\n",
    "print(f\"Store-SKU combinations: {df.groupby(['store_id', 'sku_id']).ngroups}\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Types and Missing Values:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "info_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Type': df.dtypes.values,\n",
    "    'Non-Null': df.count().values,\n",
    "    'Missing': df.isnull().sum().values,\n",
    "    'Missing %': (df.isnull().sum().values / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "display(info_df.style.background_gradient(subset=['Missing %'], cmap='Reds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stockout analysis\n",
    "if 'stockout_flag' in df.columns:\n",
    "    stockout_rate = df['stockout_flag'].mean() * 100\n",
    "    \n",
    "    # Create stockout summary\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Stockout frequency\n",
    "    stockout_counts = df.groupby('date')['stockout_flag'].sum()\n",
    "    axes[0].plot(stockout_counts.index, stockout_counts.values, alpha=0.7)\n",
    "    axes[0].set_title('Stockout Occurrences Over Time')\n",
    "    axes[0].set_xlabel('Date')\n",
    "    axes[0].set_ylabel('Number of Stockouts')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Impact on demand\n",
    "    normal_demand = df[df['stockout_flag'] == 0]['units_sold'].mean()\n",
    "    stockout_demand = df[df['stockout_flag'] == 1]['units_sold'].mean()\n",
    "    \n",
    "    demand_comparison = pd.DataFrame({\n",
    "        'Condition': ['Normal', 'Stockout'],\n",
    "        'Average Demand': [normal_demand, stockout_demand]\n",
    "    })\n",
    "    \n",
    "    axes[1].bar(demand_comparison['Condition'], demand_comparison['Average Demand'], \n",
    "                color=['green', 'red'], alpha=0.7)\n",
    "    axes[1].set_title('Demand Impact of Stockouts')\n",
    "    axes[1].set_ylabel('Average Units Sold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nStockout Statistics:\")\n",
    "    print(f\"  â€¢ Stockout Rate: {stockout_rate:.2f}%\")\n",
    "    print(f\"  â€¢ Total Stockout Days: {df['stockout_flag'].sum()}\")\n",
    "    print(f\"  â€¢ Average Demand (Normal): {normal_demand:.2f} units\")\n",
    "    print(f\"  â€¢ Average Demand (Stockout): {stockout_demand:.2f} units\")\n",
    "    print(f\"  â€¢ Stockout Impact: {((stockout_demand - normal_demand) / normal_demand * 100):.1f}%\")\n",
    "else:\n",
    "    print(\"No stockout data available in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Demand Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand distribution analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribution plot\n",
    "axes[0, 0].hist(df['units_sold'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(df['units_sold'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"units_sold\"].mean():.1f}')\n",
    "axes[0, 0].axvline(df['units_sold'].median(), color='green', linestyle='--', label=f'Median: {df[\"units_sold\"].median():.1f}')\n",
    "axes[0, 0].set_title('Distribution of Units Sold')\n",
    "axes[0, 0].set_xlabel('Units Sold')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Box plot by store\n",
    "df.boxplot(column='units_sold', by='store_id', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Demand Distribution by Store')\n",
    "axes[0, 1].set_xlabel('Store ID')\n",
    "axes[0, 1].set_ylabel('Units Sold')\n",
    "plt.sca(axes[0, 1])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Box plot by SKU\n",
    "df.boxplot(column='units_sold', by='sku_id', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Demand Distribution by SKU')\n",
    "axes[1, 0].set_xlabel('SKU ID')\n",
    "axes[1, 0].set_ylabel('Units Sold')\n",
    "plt.sca(axes[1, 0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Time series of average daily demand\n",
    "daily_demand = df.groupby('date')['units_sold'].mean()\n",
    "axes[1, 1].plot(daily_demand.index, daily_demand.values, alpha=0.7)\n",
    "axes[1, 1].set_title('Average Daily Demand Over Time')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Average Units Sold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nDemand Statistics:\")\n",
    "print(f\"  â€¢ Mean: {df['units_sold'].mean():.2f} units\")\n",
    "print(f\"  â€¢ Median: {df['units_sold'].median():.2f} units\")\n",
    "print(f\"  â€¢ Std Dev: {df['units_sold'].std():.2f} units\")\n",
    "print(f\"  â€¢ Min: {df['units_sold'].min():.0f} units\")\n",
    "print(f\"  â€¢ Max: {df['units_sold'].max():.0f} units\")\n",
    "print(f\"  â€¢ Coefficient of Variation: {(df['units_sold'].std() / df['units_sold'].mean()):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store-SKU performance heatmap\n",
    "performance_matrix = df.pivot_table(\n",
    "    values='units_sold',\n",
    "    index='store_id',\n",
    "    columns='sku_id',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(performance_matrix, annot=True, fmt='.1f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Average Units Sold'})\n",
    "plt.title('Store-SKU Performance Matrix\\n(Average Daily Units Sold)')\n",
    "plt.xlabel('SKU ID')\n",
    "plt.ylabel('Store ID')\n",
    "plt.show()\n",
    "\n",
    "# Top and bottom performers\n",
    "all_combos = df.groupby(['store_id', 'sku_id'])['units_sold'].mean().sort_values()\n",
    "print(\"\\nTop 3 Performers:\")\n",
    "for (store, sku), demand in all_combos.tail(3).items():\n",
    "    print(f\"  â€¢ {store}-{sku}: {demand:.2f} units/day\")\n",
    "\n",
    "print(\"\\nBottom 3 Performers:\")\n",
    "for (store, sku), demand in all_combos.head(3).items():\n",
    "    print(f\"  â€¢ {store}-{sku}: {demand:.2f} units/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Price distributions\n",
    "price_data = pd.DataFrame({\n",
    "    'Base Price': df['base_price'],\n",
    "    'Final Price': df['final_price'],\n",
    "    'Competitor Price': df['competitor_price']\n",
    "})\n",
    "\n",
    "price_data.boxplot(ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Price Distributions Comparison')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Discount distribution\n",
    "df['discount'] = df['base_price'] - df['final_price']\n",
    "df['discount_pct'] = (df['discount'] / df['base_price'] * 100)\n",
    "\n",
    "axes[0, 1].hist(df[df['discount'] > 0]['discount_pct'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of Discount Percentages\\n(When Discounted)')\n",
    "axes[0, 1].set_xlabel('Discount %')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Price competitiveness\n",
    "df['price_vs_comp'] = df['final_price'] / df['competitor_price']\n",
    "axes[1, 0].hist(df['price_vs_comp'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(1.0, color='red', linestyle='--', label='Price Parity')\n",
    "axes[1, 0].set_title('Price Competitiveness\\n(Final Price / Competitor Price)')\n",
    "axes[1, 0].set_xlabel('Price Ratio')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter: Price vs Demand\n",
    "axes[1, 1].scatter(df['final_price'], df['units_sold'], alpha=0.5)\n",
    "axes[1, 1].set_title('Price vs Demand Relationship')\n",
    "axes[1, 1].set_xlabel('Final Price ($)')\n",
    "axes[1, 1].set_ylabel('Units Sold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trendline\n",
    "z = np.polyfit(df['final_price'], df['units_sold'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1, 1].plot(df['final_price'].sort_values(), p(df['final_price'].sort_values()), \n",
    "               \"r--\", alpha=0.8, label=f'Trend: y = {z[0]:.2f}x + {z[1]:.2f}')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Price statistics\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(f\"  â€¢ Base Price Mean: ${df['base_price'].mean():.2f}\")\n",
    "print(f\"  â€¢ Final Price Mean: ${df['final_price'].mean():.2f}\")\n",
    "print(f\"  â€¢ Average Discount: ${df['discount'].mean():.2f} ({df[df['discount'] > 0]['discount_pct'].mean():.1f}%)\")\n",
    "print(f\"  â€¢ Competitor Price Mean: ${df['competitor_price'].mean():.2f}\")\n",
    "print(f\"  â€¢ Undercut Rate: {(df['final_price'] < df['competitor_price']).mean() * 100:.1f}%\")\n",
    "print(f\"  â€¢ Average Price Ratio (vs Competitor): {df['price_vs_comp'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Price Elasticity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price elasticity by SKU\n",
    "elasticities = []\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, sku in enumerate(df['sku_id'].unique()):\n",
    "    if idx < 3:  # Plot first 3 SKUs\n",
    "        sku_data = df[df['sku_id'] == sku].copy()\n",
    "        sku_data = sku_data[sku_data['units_sold'] > 0]  # Remove zeros for log\n",
    "        \n",
    "        if len(sku_data) > 10:\n",
    "            # Log-log regression for elasticity\n",
    "            log_price = np.log(sku_data['final_price'])\n",
    "            log_demand = np.log(sku_data['units_sold'])\n",
    "            \n",
    "            # Remove infinite values\n",
    "            mask = np.isfinite(log_price) & np.isfinite(log_demand)\n",
    "            if mask.sum() > 10:\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "                    log_price[mask], log_demand[mask]\n",
    "                )\n",
    "                \n",
    "                elasticities.append({\n",
    "                    'SKU': sku,\n",
    "                    'Elasticity': slope,\n",
    "                    'R_squared': r_value**2,\n",
    "                    'P_value': p_value,\n",
    "                    'Interpretation': 'Elastic' if abs(slope) > 1 else 'Inelastic'\n",
    "                })\n",
    "                \n",
    "                # Plot\n",
    "                axes[idx].scatter(log_price[mask], log_demand[mask], alpha=0.5)\n",
    "                axes[idx].plot(log_price[mask], slope * log_price[mask] + intercept, \n",
    "                             'r-', label=f'Elasticity: {slope:.2f}')\n",
    "                axes[idx].set_title(f'{sku} Price Elasticity')\n",
    "                axes[idx].set_xlabel('Log(Price)')\n",
    "                axes[idx].set_ylabel('Log(Demand)')\n",
    "                axes[idx].legend()\n",
    "                axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display elasticity results\n",
    "elasticity_df = pd.DataFrame(elasticities)\n",
    "print(\"\\nPrice Elasticity by SKU:\")\n",
    "display(elasticity_df.style.background_gradient(subset=['Elasticity'], cmap='RdYlGn_r'))\n",
    "\n",
    "if len(elasticity_df) > 0:\n",
    "    print(f\"\\nðŸ“ˆ Average Price Elasticity: {elasticity_df['Elasticity'].mean():.3f}\")\n",
    "    print(f\"   â€¢ Interpretation: A 1% price increase leads to {abs(elasticity_df['Elasticity'].mean()):.2f}% demand decrease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Promotion Effect Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promotion analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Promotion frequency over time\n",
    "promo_daily = df.groupby('date')['promo_flag'].mean() * 100\n",
    "axes[0, 0].plot(promo_daily.index, promo_daily.values, alpha=0.7)\n",
    "axes[0, 0].set_title('Promotion Frequency Over Time')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('% of Products on Promotion')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Demand comparison: Promo vs No Promo\n",
    "promo_comparison = df.groupby('promo_flag')['units_sold'].mean()\n",
    "axes[0, 1].bar(['No Promo', 'Promo'], promo_comparison.values, \n",
    "              color=['blue', 'orange'], alpha=0.7)\n",
    "axes[0, 1].set_title('Average Demand: Promotion Impact')\n",
    "axes[0, 1].set_ylabel('Average Units Sold')\n",
    "\n",
    "# Promotion depth distribution\n",
    "if 'promo_depth' in df.columns:\n",
    "    promo_depths = df[df['promo_flag'] == 1]['promo_depth'] * 100\n",
    "    axes[1, 0].hist(promo_depths, bins=20, edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_title('Distribution of Promotion Depths')\n",
    "    axes[1, 0].set_xlabel('Discount %')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Relationship between discount depth and demand lift\n",
    "    promo_data = df[df['promo_flag'] == 1].copy()\n",
    "    if len(promo_data) > 10:\n",
    "        axes[1, 1].scatter(promo_data['promo_depth'] * 100, promo_data['units_sold'], alpha=0.5)\n",
    "        axes[1, 1].set_title('Discount Depth vs Demand')\n",
    "        axes[1, 1].set_xlabel('Discount %')\n",
    "        axes[1, 1].set_ylabel('Units Sold')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Promotion statistics\n",
    "promo_rate = df['promo_flag'].mean() * 100\n",
    "no_promo_demand = df[df['promo_flag'] == 0]['units_sold'].mean()\n",
    "promo_demand = df[df['promo_flag'] == 1]['units_sold'].mean()\n",
    "promo_lift = (promo_demand - no_promo_demand) / no_promo_demand * 100\n",
    "\n",
    "print(\"\\nðŸŽ¯ Promotion Analysis:\")\n",
    "print(f\"  â€¢ Promotion Rate: {promo_rate:.1f}%\")\n",
    "print(f\"  â€¢ Average Demand (No Promo): {no_promo_demand:.2f} units\")\n",
    "print(f\"  â€¢ Average Demand (With Promo): {promo_demand:.2f} units\")\n",
    "print(f\"  â€¢ Promotion Lift: {promo_lift:.1f}%\")\n",
    "\n",
    "if 'promo_depth' in df.columns:\n",
    "    avg_discount = df[df['promo_flag'] == 1]['promo_depth'].mean() * 100\n",
    "    print(f\"  â€¢ Average Discount Depth: {avg_discount:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal patterns\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['day_name'] = df['date'].dt.day_name()\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Day of week patterns\n",
    "dow_demand = df.groupby('day_name')['units_sold'].mean()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_demand = dow_demand.reindex(day_order)\n",
    "\n",
    "axes[0, 0].bar(range(7), dow_demand.values, tick_label=day_order, alpha=0.7)\n",
    "axes[0, 0].set_title('Average Demand by Day of Week')\n",
    "axes[0, 0].set_ylabel('Average Units Sold')\n",
    "axes[0, 0].set_xticklabels(day_order, rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Weekly patterns\n",
    "weekly_demand = df.groupby('week_of_year')['units_sold'].mean()\n",
    "axes[0, 1].plot(weekly_demand.index, weekly_demand.values, alpha=0.7)\n",
    "axes[0, 1].set_title('Average Demand by Week of Year')\n",
    "axes[0, 1].set_xlabel('Week of Year')\n",
    "axes[0, 1].set_ylabel('Average Units Sold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly patterns\n",
    "monthly_demand = df.groupby('month')['units_sold'].mean()\n",
    "axes[1, 0].bar(monthly_demand.index, monthly_demand.values, alpha=0.7)\n",
    "axes[1, 0].set_title('Average Demand by Month')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Units Sold')\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Weekend vs Weekday\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "weekend_comparison = df.groupby('is_weekend')['units_sold'].mean()\n",
    "axes[1, 1].bar(['Weekday', 'Weekend'], weekend_comparison.values, \n",
    "              color=['gray', 'green'], alpha=0.7)\n",
    "axes[1, 1].set_title('Weekday vs Weekend Demand')\n",
    "axes[1, 1].set_ylabel('Average Units Sold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Temporal statistics\n",
    "print(\"\\nTemporal Patterns:\")\n",
    "print(f\"  â€¢ Peak Day: {dow_demand.idxmax()} ({dow_demand.max():.2f} units)\")\n",
    "print(f\"  â€¢ Low Day: {dow_demand.idxmin()} ({dow_demand.min():.2f} units)\")\n",
    "print(f\"  â€¢ Weekend vs Weekday: {(weekend_comparison[1] - weekend_comparison[0]) / weekend_comparison[0] * 100:.1f}% difference\")\n",
    "print(f\"  â€¢ Peak Week: Week {weekly_demand.idxmax()} ({weekly_demand.max():.2f} units)\")\n",
    "print(f\"  â€¢ Weekly Volatility (CV): {(weekly_demand.std() / weekly_demand.mean()):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Holiday and Weather Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holiday and weather analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Holiday impact\n",
    "holiday_comparison = df.groupby('holiday_flag')['units_sold'].mean()\n",
    "axes[0, 0].bar(['Regular Day', 'Holiday'], holiday_comparison.values, \n",
    "              color=['blue', 'red'], alpha=0.7)\n",
    "axes[0, 0].set_title('Holiday Impact on Demand')\n",
    "axes[0, 0].set_ylabel('Average Units Sold')\n",
    "\n",
    "# Weather distribution\n",
    "axes[0, 1].hist(df['weather_index'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Weather Index Distribution')\n",
    "axes[0, 1].set_xlabel('Weather Index (0-1)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Weather vs Demand\n",
    "axes[1, 0].scatter(df['weather_index'], df['units_sold'], alpha=0.3)\n",
    "axes[1, 0].set_title('Weather Impact on Demand')\n",
    "axes[1, 0].set_xlabel('Weather Index')\n",
    "axes[1, 0].set_ylabel('Units Sold')\n",
    "\n",
    "# Add trendline\n",
    "z = np.polyfit(df['weather_index'], df['units_sold'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1, 0].plot(df['weather_index'].sort_values(), p(df['weather_index'].sort_values()), \n",
    "               \"r--\", alpha=0.8, label=f'Trend: y = {z[0]:.2f}x + {z[1]:.2f}')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Weather segments analysis\n",
    "df['weather_segment'] = pd.cut(df['weather_index'], \n",
    "                               bins=[0, 0.33, 0.66, 1.0],\n",
    "                               labels=['Poor', 'Fair', 'Good'])\n",
    "weather_demand = df.groupby('weather_segment')['units_sold'].mean()\n",
    "axes[1, 1].bar(['Poor', 'Fair', 'Good'], weather_demand.values, \n",
    "              color=['gray', 'yellow', 'green'], alpha=0.7)\n",
    "axes[1, 1].set_title('Demand by Weather Condition')\n",
    "axes[1, 1].set_ylabel('Average Units Sold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Holiday and weather statistics\n",
    "holiday_rate = df['holiday_flag'].mean() * 100\n",
    "no_holiday_demand = df[df['holiday_flag'] == 0]['units_sold'].mean()\n",
    "holiday_demand = df[df['holiday_flag'] == 1]['units_sold'].mean()\n",
    "holiday_lift = (holiday_demand - no_holiday_demand) / no_holiday_demand * 100\n",
    "\n",
    "weather_corr = df['weather_index'].corr(df['units_sold'])\n",
    "\n",
    "print(\"\\nHoliday Impact:\")\n",
    "print(f\"  â€¢ Holiday Rate: {holiday_rate:.1f}%\")\n",
    "print(f\"  â€¢ Average Demand (Regular): {no_holiday_demand:.2f} units\")\n",
    "print(f\"  â€¢ Average Demand (Holiday): {holiday_demand:.2f} units\")\n",
    "print(f\"  â€¢ Holiday Lift: {holiday_lift:.1f}%\")\n",
    "\n",
    "print(\"\\nWeather Impact:\")\n",
    "print(f\"  â€¢ Weather Index Mean: {df['weather_index'].mean():.3f}\")\n",
    "print(f\"  â€¢ Correlation with Demand: {weather_corr:.3f}\")\n",
    "for condition in ['Poor', 'Fair', 'Good']:\n",
    "    if condition in weather_demand.index:\n",
    "        print(f\"  â€¢ {condition} Weather: {weather_demand[condition]:.2f} units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "num_cols = ['units_sold', 'final_price', 'base_price', 'competitor_price',\n",
    "            'promo_flag', 'promo_depth', 'holiday_flag', 'weather_index']\n",
    "\n",
    "# Filter to available columns\n",
    "available_cols = [col for col in num_cols if col in df.columns]\n",
    "corr_matrix = df[available_cols].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, vmin=-1, vmax=1, mask=mask,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Display correlations with units_sold\n",
    "corr_with_demand = corr_matrix['units_sold'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelations with Units Sold:\")\n",
    "for feature, corr in corr_with_demand.items():\n",
    "    if feature != 'units_sold':\n",
    "        strength = 'Strong' if abs(corr) > 0.5 else 'Moderate' if abs(corr) > 0.3 else 'Weak'\n",
    "        direction = 'Positive' if corr > 0 else 'Negative'\n",
    "        print(f\"  â€¢ {feature:20s}: {corr:7.3f} ({strength} {direction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate key insights\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Price elasticity insight\n",
    "if len(elasticity_df) > 0:\n",
    "    avg_elasticity = elasticity_df['Elasticity'].mean()\n",
    "    insights.append(f\"1. Average price elasticity is {avg_elasticity:.2f}, indicating {'elastic' if abs(avg_elasticity) > 1 else 'inelastic'} demand\")\n",
    "else:\n",
    "    insights.append(\"1. Price elasticity analysis requires more data points\")\n",
    "\n",
    "# Promotion effectiveness\n",
    "insights.append(f\"2. Promotions increase demand by {promo_lift:.1f}% on average\")\n",
    "\n",
    "# Holiday impact\n",
    "insights.append(f\"3. Holidays boost demand by {holiday_lift:.1f}%\")\n",
    "\n",
    "# Weather correlation\n",
    "if abs(weather_corr) > 0.1:\n",
    "    insights.append(f\"4. Weather has {'positive' if weather_corr > 0 else 'negative'} impact on demand (correlation: {weather_corr:.3f})\")\n",
    "else:\n",
    "    insights.append(f\"4. Weather shows minimal impact on demand (correlation: {weather_corr:.3f})\")\n",
    "\n",
    "# Price competitiveness\n",
    "undercut_rate = (df['final_price'] < df['competitor_price']).mean() * 100\n",
    "insights.append(f\"5. Products are priced below competitors {undercut_rate:.1f}% of the time\")\n",
    "\n",
    "# Stockout impact\n",
    "if 'stockout_flag' in df.columns:\n",
    "    stockout_rate = df['stockout_flag'].mean() * 100\n",
    "    if stockout_rate > 0:\n",
    "        insights.append(f\"6. Stockouts occur {stockout_rate:.1f}% of the time, significantly impacting demand estimation\")\n",
    "\n",
    "# Store variation\n",
    "store_demand = df.groupby('store_id')['units_sold'].mean()\n",
    "store_cv = store_demand.std() / store_demand.mean()\n",
    "insights.append(f\"7. High variation across stores (CV: {store_cv:.2f}), suggesting location-specific strategies needed\")\n",
    "\n",
    "# Weekly patterns\n",
    "weekly_demand = df.groupby('week_of_year')['units_sold'].mean()\n",
    "weekly_cv = weekly_demand.std() / weekly_demand.mean()\n",
    "if weekly_cv > 0.2:\n",
    "    insights.append(f\"8. Strong weekly seasonality detected (CV: {weekly_cv:.2f})\")\n",
    "\n",
    "for insight in insights:\n",
    "    print(f\"\\n{insight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS FOR MODELING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = [\n",
    "    \"1. Include lagged demand features (7-day, 14-day) to capture autocorrelation\",\n",
    "    \"2. Create price elasticity features that vary by SKU\",\n",
    "    \"3. Engineer interaction terms between price and promotions\",\n",
    "    \"4. Account for stockouts using censored demand estimation\",\n",
    "    \"5. Use store-specific fixed effects or hierarchical modeling\",\n",
    "    \"6. Include competitor price gap as a key feature\",\n",
    "    \"7. Model holiday and weather effects with appropriate transformations\",\n",
    "    \"8. Consider separate models for each SKU given different elasticities\",\n",
    "    \"9. Implement ensemble methods to capture non-linear relationships\",\n",
    "    \"10. Use time-based validation to avoid data leakage\"\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"\\n{rec}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EDA COMPLETE - Ready for modeling phase\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save key results to CSV for later use\n",
    "results = {\n",
    "    'metric': [\n",
    "        'avg_demand',\n",
    "        'demand_std',\n",
    "        'promo_lift_pct',\n",
    "        'holiday_lift_pct',\n",
    "        'avg_elasticity',\n",
    "        'weather_correlation',\n",
    "        'stockout_rate',\n",
    "        'undercut_rate'\n",
    "    ],\n",
    "    'value': [\n",
    "        df['units_sold'].mean(),\n",
    "        df['units_sold'].std(),\n",
    "        promo_lift,\n",
    "        holiday_lift,\n",
    "        elasticity_df['Elasticity'].mean() if len(elasticity_df) > 0 else -1.5,\n",
    "        weather_corr,\n",
    "        df['stockout_flag'].mean() * 100 if 'stockout_flag' in df.columns else 0,\n",
    "        undercut_rate\n",
    "    ]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('eda_results.csv', index=False)\n",
    "\n",
    "print(\"EDA results saved to 'eda_results.csv'\")\n",
    "print(\"\\nSummary of Key Metrics:\")\n",
    "display(results_df.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
